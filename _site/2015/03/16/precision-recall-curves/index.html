<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.5.1 by Michael Rose
  Copyright 2017 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE.txt
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin SEO -->









<title>Precision-recall curves - MI Regression</title>




<meta name="description" content="ROC curves are not very good for evaluating model fit with sparse outcomes, like civil war onset or coups. Use precision-recall curves instead.">




<meta name="author" content="Andreas Beger">

<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="MI Regression">
<meta property="og:title" content="Precision-recall curves">


  <link rel="canonical" href="http://localhost:4000/2015/03/16/precision-recall-curves/">
  <meta property="og:url" content="http://localhost:4000/2015/03/16/precision-recall-curves/">



  <meta property="og:description" content="ROC curves are not very good for evaluating model fit with sparse outcomes, like civil war onset or coups. Use precision-recall curves instead.">





  

  





  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2015-03-16T16:00:04+02:00">








  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Andreas Beger",
      "url" : "http://localhost:4000",
      "sameAs" : ["https://twitter.com/andybeega","https://www.linkedin.com/in/andreas-beger-67728a36","https://plus.google.com/111153267456095139645","https://scholar.google.com/citations?user=0QX5DXoAAAAJ"]
    }
  </script>



  <meta name="google-site-verification" content="cuymuwKhb4ZRPa4fX0BANEZvI3px-I4kRwScJhVEV1I" />




<!-- end SEO -->


<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="MI Regression Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->

<meta http-equiv="cleartype" content="on">

<!-- MathJax support (took out async) -->
<script type="text/javascript" 
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

    <!-- start custom head snippets -->

<!-- insert favicons. use http://realfavicongenerator.net/ -->

<!-- end custom head snippets -->
  </head>

  <body class="layout--single">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <a class="site-title" href="http://localhost:4000/">MI Regression</a>
        <ul class="visible-links">
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/year-archive/">Blog archive</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/papers/">Projects & Papers</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/about/">About</a></li>
          
        </ul>
        <button><div class="navicon"></div></button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    



<div id="main" role="main">
  
  <div class="sidebar sticky">
  

<div itemscope itemtype="http://schema.org/Person">

  
    <div class="author__avatar">
      
        <img src="http://localhost:4000/images/mugshot2017.jpg" class="author__avatar" alt="Andreas Beger" itemprop="image">
      
    </div>
  

  <div class="author__content">
    <h3 class="author__name" itemprop="name">Andreas Beger</h3>
    
      <p class="author__bio" itemprop="description">
        Conflict forecasting, data science
      </p>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="http://schema.org/Place">
          <i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> <span itemprop="name">Tallinn, Estonia</span>
        </li>
      

      

      
        <li>
          <a href="mailto:adbeger+mireg@gmail.com">
            <meta itemprop="email" content="adbeger+mireg@gmail.com" />
            <i class="fa fa-fw fa-envelope-square" aria-hidden="true"></i> Email
          </a>
        </li>
      

      

      
        <li>
          <a href="https://twitter.com/andybeega" itemprop="sameAs">
            <i class="fa fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter
          </a>
        </li>
      

      

      

      

      

      

      

      

      
        <li>
          <a href="https://github.com/andybega" itemprop="sameAs">
            <i class="fa fa-fw fa-github" aria-hidden="true"></i> GitHub
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs">
      <i class="fa fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="Precision-recall curves">
    <meta itemprop="description" content="ROC curves are not very good for evaluating model fit with sparse outcomes, like civil war onset or coups. Use precision-recall curves instead.">
    <meta itemprop="datePublished" content="March 16, 2015">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 class="page__title" itemprop="headline">Precision-recall curves
</h1>
          
            <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 




  8 minute read
</p>
          
        </header>
      

      <section class="page__content" itemprop="text">
        <p class="notice--info"><strong>Update 2016-06</strong>: there’s a PDF of this now, at <a href="http://ssrn.com/abstract=2765419">http://ssrn.com/abstract=2765419</a></p>

<p><a href="http://en.wikipedia.org/wiki/Receiver_operating_characteristic">ROC curves</a>
are a fairly standard way to evaluate model fit with binary outcomes, like
(civil) war onset. I would be willing to bet that most if not all quantitative
political scientists know what they are and how to construct one. Unlike
simpler fit statistics like accuracy or percentage reduction in error (PRE),
they do not depend on the particular threshold value used to divide
probabilistic predictions into binary predictions, and thus give a better
sense of the tradeoff between true and false positives inherent in any
probabilistic model. The area under a ROC curve (AUC) can summarize a model’s
performance and has the somewhat intuitive alternative interpretation of
representing the probability that a randomly picked positive outcome case will
have been ranked higher by the model than a randomly picked negative outcome
case. What I didn’t realize until more recently though is that ROC curves are
a misleading indication of model performance with kind of sparse data that
happens to be the norm in conflict research.</p>

<p>
$$
\begin{array}{c|cc}
Y &amp; p &lt; \theta &amp; p \geq \theta \\
\hline
0 &amp; \text{True Neg.} &amp; \text{False Pos.} \\
1 &amp; \text{False Neg.} &amp; \text{True Pos.} 
\end{array}
$$
</p>

<p>To recap, the basic situation is that we have a binary outcome, but a stream
of predictions that as probabilities range between 0 and 1, and the challenge
is how to map this onto the binary outcomes. We could calculate Brier scores
and avoid the problem, or we could choose a particular threshold and calculate
things like accuracy, percentage reduction in error, etc. These measures rely
on how positive predictions match up with observed outcomes (see the confusion
table above), but the drawback is that they depend on a particular threshold
value, and will change as the threshold changes. A way around this is to
record and plot all possible combinations over the range of possible threshold
values, and this is essentially what ROC curves are.</p>

<div style="width:40%;padding:0 0 0 150px;">
<table>
<tbody>
<tr>
<td>Observed</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>...</td>
</tr>
<tr>
<td>Predicted</td>
<td>0.1</td>
<td>0.6</td>
<td>0.4</td>
<td>0.8</td>
<td>...</td>
</tr>
</tbody>
</table>
</div>

<p>To construct a ROC curve, you would pick all possible thresholds, bin
predictions to 0 or 1, and then calculate the true positive rate and false
positive rate associated with each threshold, giving you the data you would
need to plot the ROC curve. The true and false positive rates are calculated
as the ratio of true positives (cases the model got right) to overall
positives in the data, and the ratio of false positives (cases the model
predicted 1, but that did not have a positive outcome) to overall negatives in
the data. Here’s an example using some simulated data I’ll discuss more below:</p>

<div style="width:50%;padding:0 0 0 150px;">
<p><!-- Thu Mar 12 11:57:35 2015 --></p>
<table>
<tbody>
<tr>
<th>Threshold</th>
<th>TPR</th>
<th>FPR</th>
</tr>
<tr>
<td align="right">0.99998</td>
<td align="right">0.00000</td>
<td align="right">0.00000</td>
</tr>
<tr>
<td align="right">0.99998</td>
<td align="right">0.00048</td>
<td align="right">0.00000</td>
</tr>
<tr>
<td align="right">0.99974</td>
<td align="right">0.00048</td>
<td align="right">0.00034</td>
</tr>
<tr>
<td align="right">0.99953</td>
<td align="right">0.00097</td>
<td align="right">0.00034</td>
</tr>
<tr>
<td align="right">0.99946</td>
<td align="right">0.00145</td>
<td align="right">0.00034</td>
</tr>
<tr>
<td align="right">0.99942</td>
<td align="right">0.00194</td>
<td align="right">0.00034</td>
</tr>
</tbody>
</table>
</div>

<p>Which gives the following ROC curve if we plot the TP and FP rates:</p>

<figure>
  
<a href="http://localhost:4000/content/2015/roc-example.png"><img src="http://localhost:4000/content/2015/roc-example.png" alt="ROC curve for the example data" /></a>

  <figcaption>
ROC curve for the example data
</figcaption>
</figure>

<p>In this example, about 40% of outcomes are positive, but this is rarely the
case in international relations and conflict research in particular, where
data tend to be sparse, with much fewer positive outcomes for things like war
or civil war onset and occurrence. <a href="http://jou
rnals.cambridge.org/action/displayAbstract?fromPage=online&amp;aid=142717&amp;fileId=S
0003055403000534">Fearon and Laitin’s 2003 paper</a> on civil war onset has 167 positives per 10,000, and the two
projects I mostly work on these days have rates of 17 per 10,000 for country-
month <a href="http://predictiveheuristics.com/2014/05/22/the-coup-in-thailand-and-
progress-in-forecasting/">irregular leadership
changes</a> and 1-5 per 10,000 for <a href="http://andybeger.com/2014/08/08/modeling-and-predicting-ieds/">IEDs in
Afghanistan</a>.</p>

<p>With sparse data it becomes pretty easy for any model to correctly predict
negatives. Because the ROC curve in part plots false positive rates that are
calculated with the resulting large number of true negatives in the
denominator, by that metric we will seem to be doing pretty well. The table
below shows a contrived example using numbers similar to what one might get
with the Fearon &amp; Laitin 2003 data and a reasonably good model. With these
number we get 50% recall (recall is the same as TPR) and a false positive rate
of only 9%. In the ROC world, we are doing well. Except that looking at the
table it is obvious that the model predictions are still problematic: for
every correct positive prediction our model makes, there are 10 false
positives.</p>

<p>
$$
\begin{array}{c|cc}
Y &amp; p &lt; \theta &amp; p \geq \theta \\
\hline
0 &amp; 10,000 &amp; 1,000 \\
1 &amp; 100 &amp; 100 
\end{array}
$$
</p>

<p>Since it becomes easier to predict negatives as they become more common,
looking at false positive rates with sparse data might not be that
informative. Instead, let’s plot something else. The only option, assuming
that we do care about positives and hence the true positive rate or recall,
would be to compare false positives to the overall number of positive
predictions made by a model for a given threshold. This is called precision,
and I think of it as how believable a model’s predictions are (“My model says
1, what are the actual chances this is true?”).</p>

<p>The plot below is a precision-recall curve that does this, for the same
example as before. Instead of FPR we now have precision, and I’ve also flipped
the axes as it seems to be convention to plot recall on the x-axis.</p>

<figure>
  
<a href="http://localhost:4000/content/2015/pr-example.png"><img src="http://localhost:4000/content/2015/pr-example.png" alt="Precision-recall curve for the same example data with 0.4 positives." /></a>

  <figcaption>
Precision-recall curve for the same example data with 0.4 positives.
</figcaption>
</figure>

<h2 id="simulations">Simulations!</h2>

<p>Since the example I used had a positive rate of 0.4, the plot doesn’t really
make it obvious why one would want to look at precision-recall curves for
sparse data. To illustrate that better, below are two plots from a simulation
where I created 3 data sets with decreasing positive rates (0.4, 0.1, 0.01)
and for each data set then created 3 models designed to achieve a particular
AUC-ROC value (0.8, 0.9, 0.95).</p>

<p>The first series of plots are the ROC curves. Since the models are meant to
match a given AUC, these shouldn’t really look different, and they don’t, as
we move to the increasingly sparse datasets. The curves get a little bit
edgier on the right, but this is just because there are less positive outcomes
based on which recall/TPR are calculated. All models are doing equally well if
we use ROC curves and AUC as our metric.</p>

<p><a href="http://localhost:4000/content/2015/roc.png"><img src="http://localhost:4000/content/2015/roc.png" alt="ROC curve" /></a></p>

<p>The corresponding precision-recall plots on the other hand show the loss of
precision as one moves to sparser data, and here it becomes more obvious that
the sparse data present more of a challenge. On the right, even the 0.95 AUC
model barely touches on 0.5 precision (1 correct positive for 1 false
positive), and if we were to calculate the area under the PR curves (AUC-PR)
we’d get values much lower, 0.25 and less.</p>

<p><a href="http://localhost:4000/content/2015/rpc.png"><img src="http://localhost:4000/content/2015/rpc.png" alt="PR curves" /></a></p>

<p>A lot of conflict research is in the world of the rightmost plot, maybe
somewhere between the two rightmost plots if you are working with occurrence
and country-year data. AUC values that I always thought were great, 0.8, even
0.9 or higher, actually can hide a lot of imprecision–“room for growth” as I
like to tell myself in consolation.</p>

<p>Another thing that stands out from these plots is that you can always increase
model recall. Just lower your threshold, everything will light up as a
potential positive, and incidentally you will capture most if not all actual
positive outcomes. Getting high precision on the other hand is much more
difficult, and realistically there are hard limits here, at least with this
kind of problem. With that in mind it seems strange to me, on the few
occasions I’ve been exposed to this, that people commissioning these kinds of
forecasts aim for recall, e.g. require that models reach 0.8 or some other
threshold, rather than precision, which might make quantitative modeling more
credible to non-technical audiences. But then, my cost for false negatives,
which I would tend to have more of with this rationale, is probably also much
lower.</p>

<p>The conclusions: if you are doing (conflict) research with sparse binary data
and are interested for whatever reason in model fit, (1) your models don’t do
as well as ROC might lead one to believe, and (2) consider precision-recall
curves as an addition or alternative.</p>

<p><a href="https://github.com/andybega/auc-pr">Code to plot PR curves, calculate AUC-PR, and replicate the examples
here.</a></p>

<h2 id="what-about-brier-scores">What about Brier scores?</h2>

<p>One thing I haven’t quite wrapped my mind around is how this relates to Brier
scores, calibration, and discrimination. With ROC and PR curves we implicitly
treat the model predictions are meaningless in and of themselves. All that
matters is their relative ranking, and I can in fact transform them in any way
that doesn’t alter this ranking. For the initial example above, I can cut all
probabilities in half and I would still get the same ROC/PR information
(recall is 0.5, precision is 0.5, FPR is 0.5):</p>

<div style="width:60%;padding:0 0 0 150px;">
<table>
<tbody>
<tr>
<td>Observed</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>...</td>
</tr>
<tr>
<td>Predicted</td>
<td>0.1</td>
<td>0.6</td>
<td>0.4</td>
<td>0.8</td>
<td>...</td>
</tr>
<tr>
<td>Predicted 2</td>
<td>0.05</td>
<td>0.3</td>
<td>0.2</td>
<td>0.4</td>
<td>...</td>
</tr>
</tbody>
</table>
</div>

<p>Although I more or less know how well the models I am working on do in terms
of AUC-ROC and AUC-PR, I am not in fact sure to what extent one can take the
probabilities generated by them at face value. For one, they tend to be very
low, way below 0.1, which makes it a bit harder to assess forecast accuracy
(Did I miss, even though I’m getting the baseline right?), but then, we are
also dealing with very rare events.</p>

<p>From a modeling perspective, another question is to what extent Brier score
rankings map on to other fit measures. In the extreme upper limiting case, it
seems that a perfect model from a ROC/PR curve perspective would also imply
that the model has perfect calibration and discrimination. But I am not sure
what happens below that, which can make it challenging to decide what models
to invest more time in.</p>


        
      </section>

      <footer class="page__meta">
        
        
  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fa fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="http://localhost:4000/tags/#auc-pr" class="page__taxonomy-item" rel="tag">AUC-PR</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/tags/#auc-roc" class="page__taxonomy-item" rel="tag">AUC-ROC</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/tags/#binary-fit" class="page__taxonomy-item" rel="tag">binary fit</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/tags/#precision-recall-curves" class="page__taxonomy-item" rel="tag">precision-recall curves</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/tags/#roc-curves" class="page__taxonomy-item" rel="tag">ROC curves</a>
    
    </span>
  </p>




  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fa fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="http://localhost:4000/categories/#research" class="page__taxonomy-item" rel="tag">research</a>
    
    </span>
  </p>


        
          <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Updated:</strong> <time datetime="2015-03-16T16:00:04+02:00">March 16, 2015</time></p>
        
      </footer>

      <section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=Precision-recall+curves%20http%3A%2F%2Flocalhost%3A4000%2F2015%2F03%2F16%2Fprecision-recall-curves%2F" class="btn btn--twitter" title="Share on Twitter"><i class="fa fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2F2015%2F03%2F16%2Fprecision-recall-curves%2F" class="btn btn--facebook" title="Share on Facebook"><i class="fa fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://plus.google.com/share?url=http%3A%2F%2Flocalhost%3A4000%2F2015%2F03%2F16%2Fprecision-recall-curves%2F" class="btn btn--google-plus" title="Share on Google Plus"><i class="fa fa-fw fa-google-plus" aria-hidden="true"></i><span> Google+</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2F2015%2F03%2F16%2Fprecision-recall-curves%2F" class="btn btn--linkedin" title="Share on LinkedIn"><i class="fa fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="http://localhost:4000/2015/01/14/archigos-leader-turnovers-by-regime/" class="pagination--pager" title="Archigos leader turnovers by regime
">Previous</a>
    
    
      <a href="http://localhost:4000/2015/04/08/public-icews-data/" class="pagination--pager" title="A quick look at the public ICEWS data
">Next</a>
    
  </nav>

    </div>

    
      <div class="page__comments">
  
    
        <h4 class="page__comments-title">Leave a Comment</h4>
        <section id="disqus_thread"></section>
      
</div>
    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You May Also Enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/2017/02/10/coup-forecasts-2017/" rel="permalink">Coup forecasts for 2017
</a>
      
    </h2>
    
      <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 




  20 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Forecasts of the risk of a coup attempt for 161 countries in 2017.
</p>
  </article>
</div>
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/2016/11/22/eu-army/" rel="permalink">Support for the creation of an EU Army
</a>
      
    </h2>
    
      <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 




  1 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Some plots of a Eurobarometer question asking people about the creation of an EU Army.
</p>
  </article>
</div>
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/2016/09/14/data-management/" rel="permalink">Data management and missing data
</a>
      
    </h2>
    
      <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 




  10 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">A lot can go wrong between raw data and processed data used for analysis. Here is one post-mortem example and a plot that can help identify issues for countr...</p>
  </article>
</div>
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/2016/06/20/moving-from-wordpress-to-jekyll/" rel="permalink">Moving from Wordpress to Jekyll
</a>
      
    </h2>
    
      <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 




  6 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">I moved my home page and blog from Wordpress to Jekyll over the past week, thanks to a small break in regular work. I’ve been using Wordpress.com since 2011,...</p>
  </article>
</div>
        
      </div>
    </div>
  
</div>


    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
    
    
      <li><a href="http://github.com/andybega"><i class="fa fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    
    <li><a href="http://localhost:4000/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2017 Andreas Beger. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    <script src="http://localhost:4000/assets/js/main.min.js"></script>




  <script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-36796505-2']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>




  
      
  <div id="disqus_thread"></div>
  <script>
    var disqus_config = function () {
      this.page.url = "http://localhost:4000/2015/03/16/precision-recall-curves/";  // Replace PAGE_URL with your page's canonical URL variable
      this.page.identifier = "/2015/03/16/precision-recall-curves"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    (function() { // DON'T EDIT BELOW THIS LINE
      var d = document, s = d.createElement('script');
      s.src = 'https://mireg.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


    



  </body>
</html>
