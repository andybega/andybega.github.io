<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on Andreas Beger</title>
    <link>https://andybeger.com/tags/r/</link>
    <description>Recent content in R on Andreas Beger</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Fri, 19 Sep 2014 00:00:00 +0000</lastBuildDate><atom:link href="https://andybeger.com/tags/r/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Baby steps with R Shiny</title>
      <link>https://andybeger.com/blog/2014-09-19-baby-steps-with-r-shiny/</link>
      <pubDate>Fri, 19 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>https://andybeger.com/blog/2014-09-19-baby-steps-with-r-shiny/</guid>
      <description>Shiny is a web application framework that lets you create interactive websites representing R data visualization and analysis. The gallery has some nice examples, and it looks like a great way to make R more accessible without having to know things like JavaScript or d3. I&amp;rsquo;ve been in trying my hand at it and it seems like a great way to visualize the models underlying the forecasts I work on in Ward Lab as well as the event data on which they are in part based.</description>
    </item>
    
    <item>
      <title>Associating points with polygons in R</title>
      <link>https://andybeger.com/blog/2014-03-29-associating-points-with-polygons-in-r/</link>
      <pubDate>Sat, 29 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>https://andybeger.com/blog/2014-03-29-associating-points-with-polygons-in-r/</guid>
      <description>Some time ago I posted on how to find geographic coordinates given a list of village or city names in R. Somebody emailed me about how to do the reverse: the person had a list of villages in France along with the population in 2010, and wanted to find which administrative unit each village was located in. The problem boils down to associating points, the village coordinates, with polygons, the administrative division which they are a part of.</description>
    </item>
    
    <item>
      <title>Code for blank state panel data</title>
      <link>https://andybeger.com/blog/2013-12-11-code-for-blank-state-panel-data/</link>
      <pubDate>Wed, 11 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>https://andybeger.com/blog/2013-12-11-code-for-blank-state-panel-data/</guid>
      <description>2018-02-28 update: check out the states package on CRAN. Create panel data for independent states, includes the G&amp;amp;W and COW state lists, and some helper functions. Like sfind(700) to quickly check what country 700 is. Here&amp;rsquo;s the package page.
The short version:
Here is some R code to create arbitrary country-year or country-month data sets reflecting the Gleditsch and Ward or COW state system membership lists, using the cshapes R package.</description>
    </item>
    
    <item>
      <title>Time to learn Python</title>
      <link>https://andybeger.com/blog/2013-11-21-time-to-learn-python/</link>
      <pubDate>Thu, 21 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>https://andybeger.com/blog/2013-11-21-time-to-learn-python/</guid>
      <description>Apparently Python is taking over the world (from a post by Tal Yarkoni):
In 2013, my toolbox looks like this:
Python for text processing and miscellaneous scripting; Ruby on Rails/JavaScript for web development, except for an occasional date with Django or Flask (Python frameworks); Python (NumPy/SciPy) for numerical computing; Python (Neurosynth, NiPy etc.) for neuroimaging data analysis; Python (NumPy/SciPy/pandas/statsmodels) for statistical analysis; Python (MatPlotLib) for plotting and visualization, except for web-based visualizations (JavaScript/d3.</description>
    </item>
    
    <item>
      <title>Quick background maps in R</title>
      <link>https://andybeger.com/blog/2013-09-30-map-now/</link>
      <pubDate>Mon, 30 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>https://andybeger.com/blog/2013-09-30-map-now/</guid>
      <description>Sometimes, for whatever reason, you want to plot something fast. Last week I had some coordinates associated with event data that I was hoping were all from Egypt. But the coordinates were for locations that are only indirectly associated with the events I had, so I wanted to do a quick plot to check. The ggmap package in R makes that pretty easy.
First, some libraries we will need, and the coordinates.</description>
    </item>
    
    <item>
      <title>Database adventures</title>
      <link>https://andybeger.com/blog/2013-09-19-database-adventures/</link>
      <pubDate>Thu, 19 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>https://andybeger.com/blog/2013-09-19-database-adventures/</guid>
      <description>Recently I&amp;rsquo;ve set up both a PostgreSQL and MySQL server to host databases related to some of our projects in the Ward Lab. I should note that I have no idea what I&amp;rsquo;m doing, and this is the first time I&amp;rsquo;ve dealt with databases and how to get them working. It&amp;rsquo;s been a very humbling experience, although in the end, we now have two different databases that can be accessed remotely from a laptop through R or other tools like Quantum GIS:</description>
    </item>
    
    <item>
      <title>Plot of Duke grade inflation</title>
      <link>https://andybeger.com/blog/2013-05-08-plot-of-duke-grade-inflation/</link>
      <pubDate>Wed, 08 May 2013 00:00:00 +0000</pubDate>
      
      <guid>https://andybeger.com/blog/2013-05-08-plot-of-duke-grade-inflation/</guid>
      <description>Someone sent around a link this morning to data on grade inflation at Duke, which shows a table of average GPAs for undergraduates from 1932 on. Looking at the table you can sort of get a sense of when GPA&amp;rsquo;s really started increasing (the &amp;rsquo;60s), but it would be nicer to just plot them:
Or to plot the year over year change in average GPA, with some missing values interpolated:</description>
    </item>
    
    <item>
      <title>Building a survivor curve from observed data</title>
      <link>https://andybeger.com/blog/2012-12-22-building-a-survivor-curve-from-observed-data/</link>
      <pubDate>Sat, 22 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>https://andybeger.com/blog/2012-12-22-building-a-survivor-curve-from-observed-data/</guid>
      <description>A few weeks ago we were asked to teach the basics of (interpreting) duration models to a group of consumers without using any math. When I learned about this it involved a lot of math and Stata, and when you look around the web it&amp;rsquo;s usually presented similarly. So this was a bit of a challenge.
A nice thing about duration analysis though is that a lot of the key concepts are already explicitly graphical, like survival curves (wikipedia) and hazard rates.</description>
    </item>
    
    <item>
      <title>Scale and north arrow for maps in R</title>
      <link>https://andybeger.com/blog/2012-08-25-scale-and-north-arrow-for-maps-in-r/</link>
      <pubDate>Sat, 25 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://andybeger.com/blog/2012-08-25-scale-and-north-arrow-for-maps-in-r/</guid>
      <description>A few months ago I produced some thematic maps of Bosnia (paper) using maptools and other packages in R, but I didn&amp;rsquo;t include scales or a north arrow. It sounds simple and sp has functions for doing those things, but I couldn&amp;rsquo;t get it to work well with my maps. Here is a basic map of Bosnia&amp;rsquo;s pre-war municipalities:
library(maptools) plot(bosnia) The function map.scale() from the maps package adds a scale.</description>
    </item>
    
    <item>
      <title>Coding provinces for the Iraq Body Count data</title>
      <link>https://andybeger.com/blog/2012-03-21-coding-provinces-for-the-iraq-body-count-data/</link>
      <pubDate>Wed, 21 Mar 2012 00:00:00 +0000</pubDate>
      
      <guid>https://andybeger.com/blog/2012-03-21-coding-provinces-for-the-iraq-body-count-data/</guid>
      <description>The Iraq Body Count project collects reports of civilian deaths, and makes their event data publicly available. Each event gives the date, location, description and civilian deaths associated with an incident. Looking at a few examples [1, 2, 3], you can see that while the data values for the date and deaths are straightforward, the place values get a little bit complicated. I&amp;rsquo;m looking for the province in which incidents occurred, so the challenge is to associate each place value with a province.</description>
    </item>
    
    <item>
      <title>Which governments torture?</title>
      <link>https://andybeger.com/blog/2012-01-20-which-governments-torture/</link>
      <pubDate>Fri, 20 Jan 2012 00:00:00 +0000</pubDate>
      
      <guid>https://andybeger.com/blog/2012-01-20-which-governments-torture/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>Running RStudio on Amazon EC2</title>
      <link>https://andybeger.com/blog/2011-12-20-running-rstudio-on-amazon-ec2/</link>
      <pubDate>Tue, 20 Dec 2011 00:00:00 +0000</pubDate>
      
      <guid>https://andybeger.com/blog/2011-12-20-running-rstudio-on-amazon-ec2/</guid>
      <description>For the most part I don&amp;rsquo;t do things that are computationally so intensive that I can&amp;rsquo;t run them on my work desktop. There have been a few times however where I ran simulations or bootstrapped models, and now Bayesian models with MCMC, that take a while to run. One solution has been to run things on FSU&amp;rsquo;s high performance computing cluster. It takes a little bit of effort, for someone without a background in computer science or programming like me, and it is inconvenient in several ways.</description>
    </item>
    
  </channel>
</rss>
